{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5ht7tFgWIBRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb23b3b-d00e-4d89-bd05-59782b7b1d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics torchvision scipy --quiet\n",
        "import torch, torchvision, cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from torchvision import transforms, models\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N0gTZte2KWr6"
      },
      "outputs": [],
      "source": [
        "model = YOLO('/content/best.pt')  # Update path if needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EMvNLgKTKZCr"
      },
      "outputs": [],
      "source": [
        "VIDEO_PATH = \"/content/15sec_input_720p.mp4\"  # Update path\n",
        "\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "frame_embeddings = []\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model.predict(frame, conf=0.4, iou=0.4, verbose=False)[0]\n",
        "\n",
        "    player_dets = []\n",
        "    for box in results.boxes:\n",
        "        cls = int(box.cls.item())\n",
        "        if cls == 2:  # player\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "            player_dets.append({'bbox': [x1, y1, x2, y2], 'frame': frame.copy()})\n",
        "\n",
        "    frame_embeddings.append(player_dets)\n",
        "\n",
        "cap.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Qy3khV8oKeMO"
      },
      "outputs": [],
      "source": [
        "resnet = models.resnet18(pretrained=True)\n",
        "resnet.fc = torch.nn.Identity()\n",
        "resnet = resnet.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def extract_embedding(image, bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    crop = image[y1:y2, x1:x2]\n",
        "    if crop.shape[0] < 5 or crop.shape[1] < 5:\n",
        "        return None\n",
        "    with torch.no_grad():\n",
        "        img_tensor = transform(crop).unsqueeze(0)\n",
        "        embedding = resnet(img_tensor).squeeze(0).cpu().numpy()\n",
        "    return embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FmFcqB-NK4Ld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b61dd30e-ab2c-41ab-bb62-456a2ffa7a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tracking: 100%|██████████| 375/375 [01:54<00:00,  3.27it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# Tracking parameters\n",
        "player_id_counter = 0\n",
        "active_tracks = []\n",
        "tracked_results = []\n",
        "\n",
        "MAX_AGE = 30\n",
        "DIST_THRESHOLD = 100\n",
        "\n",
        "def get_centroid(box):\n",
        "    x1, y1, x2, y2 = box\n",
        "    return ((x1 + x2) // 2, (y1 + y2) // 2)\n",
        "\n",
        "# Main tracking loop\n",
        "for frame_data in tqdm(frame_embeddings, desc=\"Tracking\"):\n",
        "    frame_result = []\n",
        "    detections = frame_data\n",
        "    new_tracks = []\n",
        "    cost_matrix = []\n",
        "\n",
        "    # ✅ Precompute embeddings for all detections in this frame\n",
        "    for det in detections:\n",
        "        det['embedding'] = extract_embedding(det['frame'], det['bbox'])\n",
        "\n",
        "    # Step 1: Build cost matrix (distance - appearance similarity)\n",
        "    for track in active_tracks:\n",
        "        t_cx, t_cy = get_centroid(track['bbox'])\n",
        "        t_emb = track['embedding']\n",
        "        row = []\n",
        "\n",
        "        for det in detections:\n",
        "            px, py = get_centroid(det['bbox'])\n",
        "            emb = det['embedding']\n",
        "\n",
        "            if emb is None:\n",
        "                row.append(1e6)\n",
        "                continue\n",
        "\n",
        "            sim = cosine_similarity([t_emb], [emb])[0][0]\n",
        "            cost = np.linalg.norm([px - t_cx, py - t_cy]) - sim * 100  # Lower = better\n",
        "            row.append(cost)\n",
        "\n",
        "        cost_matrix.append(row)\n",
        "\n",
        "    matched_tracks = set()\n",
        "    matched_dets = set()\n",
        "\n",
        "    # Step 2: Match using Hungarian algorithm\n",
        "    if cost_matrix:\n",
        "        cost_matrix = np.array(cost_matrix)\n",
        "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
        "\n",
        "        for r, c in zip(row_ind, col_ind):\n",
        "            if cost_matrix[r][c] < DIST_THRESHOLD:\n",
        "                track = active_tracks[r]\n",
        "                det = detections[c]\n",
        "                emb = det['embedding']\n",
        "                pid = track['id']\n",
        "                new_tracks.append({\n",
        "                    'id': pid,\n",
        "                    'bbox': det['bbox'],\n",
        "                    'embedding': emb,\n",
        "                    'age': 0\n",
        "                })\n",
        "                frame_result.append({\n",
        "                    'bbox': det['bbox'],\n",
        "                    'id': pid\n",
        "                })\n",
        "                matched_tracks.add(r)\n",
        "                matched_dets.add(c)\n",
        "\n",
        "    # Step 3: Create new IDs for unmatched detections\n",
        "    for i, det in enumerate(detections):\n",
        "        if i not in matched_dets:\n",
        "            emb = det['embedding']\n",
        "            if emb is not None:\n",
        "                player_id_counter += 1\n",
        "                pid = player_id_counter\n",
        "                new_tracks.append({\n",
        "                    'id': pid,\n",
        "                    'bbox': det['bbox'],\n",
        "                    'embedding': emb,\n",
        "                    'age': 0\n",
        "                })\n",
        "                frame_result.append({\n",
        "                    'bbox': det['bbox'],\n",
        "                    'id': pid\n",
        "                })\n",
        "\n",
        "    # Step 4: Keep unmatched tracks if not too old\n",
        "    for i, track in enumerate(active_tracks):\n",
        "        if i not in matched_tracks:\n",
        "            track['age'] += 1\n",
        "            if track['age'] <= MAX_AGE:\n",
        "                new_tracks.append(track)\n",
        "\n",
        "    active_tracks = new_tracks\n",
        "    tracked_results.append(frame_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "width, height = int(cap.get(3)), int(cap.get(4))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(\"output.mp4\", fourcc, 30.0, (width, height))\n",
        "\n",
        "frame_idx = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret or frame_idx >= len(tracked_results):\n",
        "        break\n",
        "\n",
        "    for player in tracked_results[frame_idx]:\n",
        "        x1, y1, x2, y2 = player['bbox']\n",
        "        pid = player['id']\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f'ID: {pid}', (x1, y1 - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "    frame_idx += 1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n"
      ],
      "metadata": {
        "id": "uA3l9rO_U0UV"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}